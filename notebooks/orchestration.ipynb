{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plate Cutting - An Optimization Approach\n",
    "\n",
    "The purpose of this notebook is to analyze data from a plate cutter in a manufacturing environment and find ways to improve efficiency. It documents the full process of loading and cleaning raw CSV files to analyzing each column. We'll process and visualize the data to identify trends and inefficiencies. The goal is to turn raw machine logs into meaningful insights to help to optimize the cutting process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "We will check that all csv's have the same column names, and then we will concatenate all of the csv's into a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files are located in data/landing folder. We must ensure all files have the same column names or we wont be able to merge them.\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Variables\n",
    "landing_folder = \"../data/landing/files\"\n",
    "columns = ['ProgramName', 'Start', 'End', 'Cancelled', 'TotalTime', 'BreakingTime', 'NumberBreaks', 'Process1Time', 'Process1Length', 'Process1Starts', 'Process2Time', 'Process2Length', 'Process2Starts', 'Process3Time', 'Process3Length', 'Process3Starts', 'Process4Time', 'Process4Length', 'Process4Starts', 'RapidTime', 'RapidLength', 'RapidStarts']\n",
    "\n",
    "\n",
    "# Function to load a file into a pandas dataframe\n",
    "def load_file(*args, **kwargs):\n",
    "    try:\n",
    "        return pd.read_csv(*args, **kwargs)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file: {args[0]}\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# Function to read a file and compare name of columns with list of columns we expect\n",
    "def check_column_names(file, columns):\n",
    "    df = load_file(file, delimiter=';')\n",
    "\n",
    "    if not all([col in df.columns for col in columns]):\n",
    "        print(f\"Columns in {file} do not match expected columns\")\n",
    "        print(f\"Missing columns: {set(columns) - set(df.columns)}\")\n",
    "        print(f\"Extra columns: {set(df.columns) - set(columns)}\\n\\n\")\n",
    "\n",
    "\n",
    "# check if all files have correct columns\n",
    "for file in os.listdir(landing_folder):\n",
    "    check_column_names(f\"{landing_folder}/{file}\", columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved: ../data/landing/concat_file/full_file.csv\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "concatenated_file_path = \"../data/landing/concat_file/full_file.csv\"\n",
    "\n",
    "\n",
    "# Updated merge function using pd.concat()\n",
    "def merge_files(landing_folder):\n",
    "    all_files = [os.path.join(landing_folder, file) for file in os.listdir(landing_folder) if file.endswith(\".csv\")]\n",
    "    \n",
    "    df_list = [load_file(file, delimiter=\";\") for file in all_files]\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_folder(folder):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_file(df, file):\n",
    "    create_folder(os.path.dirname(file))\n",
    "    df.to_csv(file, index=False, sep=\";\")\n",
    "\n",
    "\n",
    "df = merge_files(landing_folder)\n",
    "save_file(df, concatenated_file_path)\n",
    "print(f\"File saved: {concatenated_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "desired_columns = [ #will use this list after cleaning the data to ensure correct processing\n",
    "    \"ProgramName\", \"Nest ID\", \"Start\", \"Nest start time\", \"End\", \"Nest end time\", \"Cancelled\", \"Nest cancelled Yes/No\",\n",
    "    \"TotalTime\", \"BreakingTime\", \"NumberBreaks\", \"Process1Time\", \"Process1Length\", \"Process1Starts\", \"RapidTime\",\n",
    "    \"RapidLength\", \"RapidStart\"\n",
    "]\n",
    "cleaned_file_path = \"../data/staging/cleaned_file.csv\"\n",
    "\n",
    "# True if any value is zero, drops columns with all zeros\n",
    "df = df.loc[:, (df != 0).any(axis=0)]\n",
    "\n",
    "# Check if 'ProgramName' contains only numeric values\n",
    "df = df[df['ProgramName'].astype(str).str.isnumeric()] # returns true if all characters in the string are numeric\n",
    "df['ProgramName'] = df['ProgramName'].astype(int)\n",
    "\n",
    "# Remove duplicate ProgramName rows, keep the first occurrence\n",
    "df = df.drop_duplicates(subset=['ProgramName'], keep='first')\n",
    "\n",
    "df = df[df['Cancelled'] != True] # remove rows where 'Cancelled' is True\n",
    "\n",
    "# Remove rows where key columns contain zero\n",
    "df = df[(df[['BreakingTime', 'Process1Time', 'Process1Length', 'RapidLength']] != 0).all(axis=1)]\n",
    "\n",
    "# Check if remaining columns match the desired list\n",
    "remaining_columns = df.columns\n",
    "\n",
    "if remaining_columns != desired_columns:\n",
    "    missing_columns = desired_columns - remaining_columns\n",
    "    extra_columns = remaining_columns - desired_columns\n",
    "    print(f\"Warning: Column mismatch detected!\\nMissing: {missing_columns}\\nExtra: {extra_columns}\")\n",
    "else:\n",
    "    print(\"Column validation successful. All required columns are present.\")\n",
    "\n",
    "# Save the cleaned data\n",
    "save_file(df, cleaned_file_path)\n",
    "\n",
    "print(f\"Cleaned file saved: {cleaned_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
